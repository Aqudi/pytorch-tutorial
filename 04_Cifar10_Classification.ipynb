{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 데이터셋 설명 & 사용 방법 링크\n",
    "### https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "\n",
    "# 데이터 살펴보기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"D:/NoShare/CIFAR10/cifar-10-batches-py/\"\n",
    "tmp = unpickle(base_path + \"data_batch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tmp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 59,  43,  50, ..., 140,  84,  72],\n",
       "       [154, 126, 105, ..., 139, 142, 144],\n",
       "       [255, 253, 253, ...,  83,  83,  84],\n",
       "       ...,\n",
       "       [ 71,  60,  74, ...,  68,  69,  68],\n",
       "       [250, 254, 211, ..., 215, 255, 254],\n",
       "       [ 62,  61,  60, ..., 130, 130, 131]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 각 픽셀의 값으로 0 ~ 255 이다.\n",
    "# 255로 나눠주면 Nomalize 해주는 효과가 있다. (0~1 사이의 값으로 만들어줌)\n",
    "tmp[b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "tmp[b'data'].shape"
   ]
  },
  {
   "source": [
    "# 데이터를 읽어서 Image, Label로 분리 및 학습, 검증, 테스트 용으로 분리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_images_and_labels(path):\n",
    "    data = unpickle(path)\n",
    "    # Nomalize\n",
    "    data_images = data[b'data'] / 255 \n",
    "    # Shape을 사진 형태로 만들어줌\n",
    "    data_images = data_images.reshape(-1, 3, 32, 32).astype(\"float32\")\n",
    "    data_labels = data[b'labels']\n",
    "    return data_images, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지, 라벨 불러오기\n",
    "images1, labels1 = pickle_to_images_and_labels(base_path + \"data_batch_1\")\n",
    "images2, labels2 = pickle_to_images_and_labels(base_path + \"data_batch_2\")\n",
    "images3, labels3 = pickle_to_images_and_labels(base_path + \"data_batch_3\")\n",
    "images4, labels4 = pickle_to_images_and_labels(base_path + \"data_batch_4\")\n",
    "images5, labels5 = pickle_to_images_and_labels(base_path + \"data_batch_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 용 이미지, 라벨 불러오기\n",
    "test_images, test_labels = pickle_to_images_and_labels(base_path + \"test_batch\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 5개의 데이터 배치를 합쳐서 학습 데이터셋 생성\n",
    "train_images = np.concatenate([images1, images2, images3, images4, images5], axis=0)\n",
    "train_labels = np.concatenate([labels1, labels2, labels3, labels4, labels5], axis=0)\n",
    "\n",
    "# 따로 따로 처리했을 때 문제가 발생할 수 있으므로 같이 처리해준다.\n",
    "test_images = np.concatenate([test_images], axis=0)\n",
    "test_labels = np.concatenate([test_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습 이미지에서 Validation set 분리\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    stratify=train_labels, \n",
    "    random_state=42, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "학습 이미지   shape:\t(40000, 3, 32, 32)\n학습 라벨     shape:\t(40000,)\n\n검증 이미지   shape:\t(10000, 3, 32, 32)\n검증 라벨     shape:\t(10000,)\n\n테스트 이미지 shape:\t(10000, 3, 32, 32)\n테스트 이미지 shape:\t(10000,)\n\n"
     ]
    }
   ],
   "source": [
    "print(f\"학습 이미지   shape:\\t{train_images.shape}\")\n",
    "print(f\"학습 라벨     shape:\\t{train_labels.shape}\\n\")\n",
    "\n",
    "print(f\"검증 이미지   shape:\\t{valid_images.shape}\")\n",
    "print(f\"검증 라벨     shape:\\t{valid_labels.shape}\\n\")\n",
    "\n",
    "print(f\"테스트 이미지 shape:\\t{test_images.shape}\")\n",
    "print(f\"테스트 이미지 shape:\\t{test_labels.shape}\\n\")"
   ]
  },
  {
   "source": [
    "# Tensor 형식 데이터로 만들고 DataLoader 생성하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_images_tensor = torch.tensor(train_images)\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "train_loader = DataLoader(train_tensor, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "valid_images_tensor = torch.tensor(valid_images)\n",
    "valid_labels_tensor = torch.tensor(valid_labels)\n",
    "valid_tensor = TensorDataset(valid_images_tensor, valid_labels_tensor)\n",
    "valid_loader = DataLoader(valid_tensor, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "test_images_tensor = torch.tensor(test_images)"
   ]
  },
  {
   "source": [
    "# CNN 모델 구성"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # input channels, output channels, stride\n",
    "        # Color channel이 RGB로 3\n",
    "        # padding을 1 추가 (기본이 0) -> 동일한 사이즈의 output이 나오도록 추가\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # fc layer로 갈 때 flatten 진행\n",
    "        # 64 -> 32 -> 10 은 임의의 숫자. 정해진 것이 없다.\n",
    "        # conv -> pool -> 로 나온 사이즈 -> fc -> output\n",
    "        self.fc1 = nn.Linear(8 * 8 * 16, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 32 * 32 * 3\n",
    "        x = F.relu(x)      # 32 * 32 * 8\n",
    "        x = self.pool(x)   # 16 * 16 * 8\n",
    "        x = self.conv2(x)  # 16 * 16 * 16\n",
    "        x = F.relu(x)      # 16 * 16 * 16\n",
    "        x = self.pool(x)   # 8 * 8 * 16\n",
    "\n",
    "        x = x.view(-1, 8 * 8 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "model = CNN().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model"
   ]
  },
  {
   "source": [
    "# 앞서한 것과 동일한 학습 -> 평가 -> 예측결과 정확도 확인"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "def evaluate(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE, dtype=torch.int64)\n",
    "            output = model(data)\n",
    "            valid_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    valid_accuracy = 100 * correct / len(valid_loader.dataset)\n",
    "    return valid_loss, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/40000 (0%)]\tLoss: 0.623523\n",
      "Train Epoch: 1 [6400/40000 (16%)]\tLoss: 0.964181\n",
      "Train Epoch: 1 [12800/40000 (32%)]\tLoss: 0.795917\n",
      "Train Epoch: 1 [19200/40000 (48%)]\tLoss: 1.011686\n",
      "Train Epoch: 1 [25600/40000 (64%)]\tLoss: 1.095633\n",
      "Train Epoch: 1 [32000/40000 (80%)]\tLoss: 0.745271\n",
      "Train Epoch: 1 [38400/40000 (96%)]\tLoss: 1.024399\n",
      "[EPOCH : 1], \tValidation Loss: 1.0525, \tValidation Accuracy: 63.82 % \n",
      "\n",
      "Train Epoch: 2 [0/40000 (0%)]\tLoss: 0.854092\n",
      "Train Epoch: 2 [6400/40000 (16%)]\tLoss: 0.953303\n",
      "Train Epoch: 2 [12800/40000 (32%)]\tLoss: 0.773129\n",
      "Train Epoch: 2 [19200/40000 (48%)]\tLoss: 0.753375\n",
      "Train Epoch: 2 [25600/40000 (64%)]\tLoss: 1.144141\n",
      "Train Epoch: 2 [32000/40000 (80%)]\tLoss: 0.793218\n",
      "Train Epoch: 2 [38400/40000 (96%)]\tLoss: 0.817672\n",
      "[EPOCH : 2], \tValidation Loss: 1.0263, \tValidation Accuracy: 64.97 % \n",
      "\n",
      "Train Epoch: 3 [0/40000 (0%)]\tLoss: 0.969401\n",
      "Train Epoch: 3 [6400/40000 (16%)]\tLoss: 0.890417\n",
      "Train Epoch: 3 [12800/40000 (32%)]\tLoss: 1.090084\n",
      "Train Epoch: 3 [19200/40000 (48%)]\tLoss: 0.925128\n",
      "Train Epoch: 3 [25600/40000 (64%)]\tLoss: 1.281804\n",
      "Train Epoch: 3 [32000/40000 (80%)]\tLoss: 0.980452\n",
      "Train Epoch: 3 [38400/40000 (96%)]\tLoss: 0.830476\n",
      "[EPOCH : 3], \tValidation Loss: 1.0446, \tValidation Accuracy: 64.31 % \n",
      "\n",
      "Train Epoch: 4 [0/40000 (0%)]\tLoss: 1.003027\n",
      "Train Epoch: 4 [6400/40000 (16%)]\tLoss: 1.041606\n",
      "Train Epoch: 4 [12800/40000 (32%)]\tLoss: 0.798226\n",
      "Train Epoch: 4 [19200/40000 (48%)]\tLoss: 0.833513\n",
      "Train Epoch: 4 [25600/40000 (64%)]\tLoss: 0.802433\n",
      "Train Epoch: 4 [32000/40000 (80%)]\tLoss: 0.726014\n",
      "Train Epoch: 4 [38400/40000 (96%)]\tLoss: 0.990239\n",
      "[EPOCH : 4], \tValidation Loss: 1.0371, \tValidation Accuracy: 64.21 % \n",
      "\n",
      "Train Epoch: 5 [0/40000 (0%)]\tLoss: 0.946983\n",
      "Train Epoch: 5 [6400/40000 (16%)]\tLoss: 0.809586\n",
      "Train Epoch: 5 [12800/40000 (32%)]\tLoss: 0.568640\n",
      "Train Epoch: 5 [19200/40000 (48%)]\tLoss: 0.750070\n",
      "Train Epoch: 5 [25600/40000 (64%)]\tLoss: 0.709757\n",
      "Train Epoch: 5 [32000/40000 (80%)]\tLoss: 0.800471\n",
      "Train Epoch: 5 [38400/40000 (96%)]\tLoss: 0.866566\n",
      "[EPOCH : 5], \tValidation Loss: 1.0268, \tValidation Accuracy: 64.89 % \n",
      "\n",
      "Train Epoch: 6 [0/40000 (0%)]\tLoss: 0.998826\n",
      "Train Epoch: 6 [6400/40000 (16%)]\tLoss: 0.915489\n",
      "Train Epoch: 6 [12800/40000 (32%)]\tLoss: 0.871640\n",
      "Train Epoch: 6 [19200/40000 (48%)]\tLoss: 0.887632\n",
      "Train Epoch: 6 [25600/40000 (64%)]\tLoss: 0.781111\n",
      "Train Epoch: 6 [32000/40000 (80%)]\tLoss: 0.700924\n",
      "Train Epoch: 6 [38400/40000 (96%)]\tLoss: 0.993483\n",
      "[EPOCH : 6], \tValidation Loss: 1.0531, \tValidation Accuracy: 63.90 % \n",
      "\n",
      "Train Epoch: 7 [0/40000 (0%)]\tLoss: 1.030938\n",
      "Train Epoch: 7 [6400/40000 (16%)]\tLoss: 0.785470\n",
      "Train Epoch: 7 [12800/40000 (32%)]\tLoss: 0.815208\n",
      "Train Epoch: 7 [19200/40000 (48%)]\tLoss: 0.673985\n",
      "Train Epoch: 7 [25600/40000 (64%)]\tLoss: 0.758270\n",
      "Train Epoch: 7 [32000/40000 (80%)]\tLoss: 0.952392\n",
      "Train Epoch: 7 [38400/40000 (96%)]\tLoss: 0.692602\n",
      "[EPOCH : 7], \tValidation Loss: 1.0545, \tValidation Accuracy: 63.83 % \n",
      "\n",
      "Train Epoch: 8 [0/40000 (0%)]\tLoss: 0.874533\n",
      "Train Epoch: 8 [6400/40000 (16%)]\tLoss: 0.945766\n",
      "Train Epoch: 8 [12800/40000 (32%)]\tLoss: 0.569434\n",
      "Train Epoch: 8 [19200/40000 (48%)]\tLoss: 0.909055\n",
      "Train Epoch: 8 [25600/40000 (64%)]\tLoss: 0.619162\n",
      "Train Epoch: 8 [32000/40000 (80%)]\tLoss: 0.867002\n",
      "Train Epoch: 8 [38400/40000 (96%)]\tLoss: 0.692358\n",
      "[EPOCH : 8], \tValidation Loss: 1.0353, \tValidation Accuracy: 65.04 % \n",
      "\n",
      "Train Epoch: 9 [0/40000 (0%)]\tLoss: 0.521438\n",
      "Train Epoch: 9 [6400/40000 (16%)]\tLoss: 0.915661\n",
      "Train Epoch: 9 [12800/40000 (32%)]\tLoss: 0.882478\n",
      "Train Epoch: 9 [19200/40000 (48%)]\tLoss: 0.877442\n",
      "Train Epoch: 9 [25600/40000 (64%)]\tLoss: 0.838068\n",
      "Train Epoch: 9 [32000/40000 (80%)]\tLoss: 0.920751\n",
      "Train Epoch: 9 [38400/40000 (96%)]\tLoss: 0.777306\n",
      "[EPOCH : 9], \tValidation Loss: 1.0437, \tValidation Accuracy: 64.44 % \n",
      "\n",
      "Train Epoch: 10 [0/40000 (0%)]\tLoss: 0.623860\n",
      "Train Epoch: 10 [6400/40000 (16%)]\tLoss: 0.826409\n",
      "Train Epoch: 10 [12800/40000 (32%)]\tLoss: 0.829322\n",
      "Train Epoch: 10 [19200/40000 (48%)]\tLoss: 0.618426\n",
      "Train Epoch: 10 [25600/40000 (64%)]\tLoss: 0.728788\n",
      "Train Epoch: 10 [32000/40000 (80%)]\tLoss: 0.847478\n",
      "Train Epoch: 10 [38400/40000 (96%)]\tLoss: 0.817647\n",
      "[EPOCH : 10], \tValidation Loss: 1.0311, \tValidation Accuracy: 64.96 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAINING\n",
    "\n",
    "이런 표시를 훈련 위에 둬서 시간이 오래 걸릴 수도 있으니\n",
    "EPOCHS = 1로 둬서 위의 코드들을 검증하기도 함.\n",
    "'''\n",
    "EPOCHS = 10\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(epoch, model, train_loader, optimizer)\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "    print(f\"[EPOCH : {epoch}], \\tValidation Loss: {valid_loss:.4f}, \\tValidation Accuracy: {valid_accuracy:.2f} % \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testset_prediction(model, test_images_tensor):\n",
    "    model.eval()\n",
    "    result = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_images_tensor:\n",
    "            data = data.to(DEVICE)\n",
    "            output = model(data.view(-1, 3, 32, 32))\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            result.append(prediction.tolist())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6527"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_predict_result = testset_prediction(model, test_images_tensor)\n",
    "accuracy_score(test_labels, np.squeeze(test_predict_result))"
   ]
  },
  {
   "source": [
    "# 시각화"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.919844pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.919844\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-02-09T13:31:06.174248</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.919844 \r\nL 251.565 248.919844 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 225.041719 \r\nL 244.365 225.041719 \r\nL 244.365 7.601719 \r\nL 26.925 7.601719 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pbc1609fc39)\">\r\n    <image height=\"218\" id=\"imagee269af67c7\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-7.041719\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mcce7eaa8f3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.3225\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(27.14125 239.640156)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.2975\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(61.11625 239.640156)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.2725\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(91.91 239.640156)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"132.2475\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(125.885 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"166.2225\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(159.86 239.640156)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.1975\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(193.835 239.640156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.1725\" xlink:href=\"#mcce7eaa8f3\" y=\"225.041719\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(227.81 239.640156)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m9a14fb4595\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"44.974219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 48.773437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"78.949219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"112.924219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 116.723437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"146.899219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"180.874219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9a14fb4595\" y=\"214.849219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(7.2 218.648437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 225.041719 \r\nL 26.925 7.601719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 225.041719 \r\nL 244.365 7.601719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 225.041719 \r\nL 244.365 225.041719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.601719 \r\nL 244.365 7.601719 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pbc1609fc39\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.601719\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe5klEQVR4nO2dW4xc15We/1X3S9+bbHareZVMO5JlSxYIwYkTw4mTgWIMYPvBxvhhoAdjOA9jIAYmD4IDxM6bE8Qe+MmAHAujCRyPjdiGjcBIRhAyo8wgo7Gk0dWSqIspkiLZze5mX6q67rXy0CWAUva/u8XuruZ4/x9AdHGv2uess89Z51Ttv9ba5u4QQvz2kzloB4QQw0HBLkQiKNiFSAQFuxCJoGAXIhEU7EIkQm43nc3sAQDfAZAF8F/c/Zux9+ez5sWchR3J52m/XC7spvf6tE+306a2jIV9AIBCPjIkRKbs9XuRLlzazGT4vTZm494DRo4tk83yfWX5vmLKbL/Px5/vj3sf217MFjmdFPfYvm72nHFH2HkBgE63G2xvtsLtWxsMj2+z3UW72wvuzG5WZzezLIBzAP4VgEsAfgXgS+7+a9ZnpJjxj86Gg/rw0aN0X9PT08H29kad9lm6dJ7aRkpFapufmaE273aC7eu167RPtx/uAwCVUpnaRsoVastHAtfIjXFkbIz2KY9Wqa0TuZFtNlrUVq1OBNstEiybjU1qq23yc50jDxAAyJIAbLaatE+7xY+rHDkv5Qq/rvIRH69eWw62v/qbJdrHc+Hz+XfnrmJ9sxXc2W4+xt8P4HV3f9Pd2wD+HMBnd7E9IcQ+sptgnwdw8Yb/Xxq0CSFuQXbznT30UeH/+05gZmcBnAWAAv/0KYTYZ3bzZL8E4NgN/z8K4PJ73+TuD7v7GXc/k8/exEyKEGJP2E2w/wrAaTM7ZWYFAL8H4Bd745YQYq+56Y/x7t41s68A+F/Ykt4ecfeXYn2yZhgvhmfj56b4bHGzHZ45zee4kjAyFpnNzkVkrRK3dTvhTyYjhVG+r0KB2kZHJ7gf3YicR8YDAHKF8IzwxKFDtA8isufYKD+2zFqN2gqFkfCuIjJfprhBbRaRRLMRdaJD5NmM8z6VEr8Wi5HzWSnzcYw9Vuu98HEvb/JPwqvrK8H2VpvLdbvS2d39lwB+uZttCCGGg35BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkwq5m498vGXNUs+FsNK+FpQQAODI+GWyvbfAkk+sNLguVRnjiRyPSb2IyLMlk+lxysWyJ2prg/YpV7mPb+XG3uuGEkf7qAu3Tj8hQ1QaX+SzDL5+eh8exSZKJACAXkdcOzx6htsYmT6Dxeng8piYmaJ9Khcu2xSJPdmlucunw8hJPllprhsd/4shx2uf8wrlgey+WZUktQojfKhTsQiSCgl2IRFCwC5EICnYhEmGos/HFfA6nbgsnZLhFEj82yEz96jrtMxurBxZJFvD1BrWtbYaVhH4kuWO1tUptG5HZ+MNzvDxWt84Vg9vGwokabTIrDQCdDp/BXbvGZ5ERKTGVLYRtHqnFViyHk2cAYLzHE3kaNT4b36THHSnHNjlBTbU1Xrvu7ctXqe25c29TWz0TVnk8x5WcHlE1ojUPqUUI8VuFgl2IRFCwC5EICnYhEkHBLkQiKNiFSIShSm+lchl3fvgjQVuvHlkNpBaW2FpV7n4+knCx1OCJH68vcj82LSy79CMS1FKdry5SGOfJLrXLq9SWa/Glre6aPx1sPzLKV59pR2rabURWaWlElmRqdsLj32xyabMRGatOe5HaSkU+jsV8WM7rOR/D5eur1La4GF69BQAuX+VS8OUlPsZeDifXtDZ5ctgUufab61zC1pNdiERQsAuRCAp2IRJBwS5EIijYhUgEBbsQibAr6c3MzgPYANAD0HX3M7H3O4A2kanGIjXBqqVwJlevx7OkmpE1JJ97/iK1vbS0Rm1WCUskuUgtttHRae5IntczW17mEo+1uET1f555I9h++gT349TRcI0/ADg8c5TaRkbmqK1LFvGsR+q09SNy2OK1K9S2GatBlw1ngbUjsuHSKs8qvLSwSm3Lq9yPdptLYrXaUrC9XOISMVtWLLZ06l7o7P/c3cPeCiFuGfQxXohE2G2wO4C/MLOnzezsXjgkhNgfdvsx/hPuftnMZgA8ZmavuPsTN75hcBM4CwBTo7zyhhBif9nVk93dLw/+LgL4GYD7A+952N3PuPuZkTJf21oIsb/cdLCbWdXMRt95DeB3ALy4V44JIfaW3XyMPwLgZ7ZVQDAH4L+5+/+MdWh1OnjzSlhCmZ/g8s+JiXBWU7bP71XLTV54b3mVZ15lSJYUAFTIkkxrkcKXPXA5ZjTLpZUjM3y5o2tXr1Hb6wvhApELNS7lLWxMUdsn7/sn1DY3yvt1ES7qWS7yIpvrkSXASgXer17jkt3GZrjgJGsHgKU1bqu3IktvReS8UplfqzOz4Ws/l+HXcH0jLGFG6nnefLC7+5sA7rnZ/kKI4SLpTYhEULALkQgKdiESQcEuRCIo2IVIhKEWnHQA3X5YTnj6+Zd5xw/OB5s/dJxncvU3uBzTaHL5ZL3G14HLk8KApQLPXqtHCjb2e1wCbJcr1DY+Hl4bDABypbBE1WrxgofnLvMsr3LpFb6vLJeaMt2wfNV3nv3VafNz1m9wOayS5eezZ+Hjrjsfj06T76sb8bFc5T8aKxmX0U6dYNIb7YLFhfB1enGDn0s92YVIBAW7EImgYBciERTsQiSCgl2IRBjqbHw2k8X4WHjmsT7BZ1RffDOcPDM7xZf9KRX5fWxsgi+FNAE+a9rxsI+T4zx5ptXm9eLaDT7z36itUtvkFD+2yenxYPsqL62H5iZXBf7+XLimHQC0O3zW+qMnDwfbKzk+viDjCwC5HJ/F7zlXBXJ5MlaRjBG+NSBX5CFT6/Bj6/a4/61mWBkokpqHAFAqhP3IRI5LT3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwlClNzjgnbCwMX/qDtrtjVffDLb/zdO/oX3u+8jt1DY5McptfZ7osLoe1q+8zyWjici+6jXeL1LODIhITdeXw3XcxsbCkhwAFHP8Mlhc5PXunn71MrWtrITH6gPzvNbgkUmeSGIZfszNDh/HWit8PmsNfp5bXb6vPlm+DADykTp542Uu925uhv1vN3iyjhMpzyPKpp7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSIRtpTczewTA7wJYdPe7B21TAH4E4CSA8wC+6O7hdYduoNVq4o1z54K2ieNcKkMlnFX21gUuC7V//Ta1bXR4ZtD6Ol/KaXI0nGUXy2ybmJ6htpFRLvHElpQqkVp4ALBRD2ewXb4azhwEgMMz3MfDR8LZawCwGkmle+NaeHmitSaXvI4e4nX3jkxy6SqT4dmDzXbY1o0t1VTkEmC5yv0ojnB5MxOR7Nauh+XSWp1nFRaIzOeRrM2dPNn/FMAD72l7CMDj7n4awOOD/wshbmG2DfbBeuvvvfV8FsCjg9ePAvjc3rolhNhrbvY7+xF3vwIAg7/8c6AQ4pZg338ua2ZnAZwFgGpB84FCHBQ3G30LZjYHAIO/i+yN7v6wu59x9zNFViJICLHv3Gz0/QLAg4PXDwL4+d64I4TYL3Yivf0QwKcAHDKzSwC+DuCbAH5sZl8GcAHAF3ays9FqBZ/8x/cGbU++wqWyI8fCGXEn5/lUwd/81ZPUdm2DZxNZRHZxywbbNyOFI9uLy9Q2Ns4LZmayvEBhNsulwxyRZFprYSkMAN6+zLPXqlVeTHNmbpbaGkRiW76+RPusX+Tq7bVV7v+JuQlq65OMOAcfw3vu+Qi1zd12nNoWr3Mp8vIVLn3WN8LP3GKlRPsYuRZh/Pm9bbC7+5eI6dPb9RVC3DroS7QQiaBgFyIRFOxCJIKCXYhEULALkQhDLTiZz+cwd2Q6aJu+xCWqbiMsacyf5plyd99zN7U99sRT1FYtcTmsRopl1ls8g8qafB21Xp9LdvkckVYANCKFCFvtsGRXrvBsrX5kHbJGi+/raiSTbnb2SLA9F8mwW1nistxKnReVHFnnPo6UwhLb7Owc7TM9Fb5GAeDUyRPcdgcPp1dIticALC5cDbbHJN1cjj2nd5f1JoT4LUDBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwlClt54DG/2wNDA+waWhhZVwNlSnyQvyfegD89T21tthqQMAzl/l2VXFsXBGXKbI75mZPl//qx+515bKPNustsF99D6R3go8my9f4HJj33l2WCMiK7I14uZu4+fljtMfpDZWqBQALq3wIpbzM+FxPD7BC2n2Ise8us6vuclpngV4223HqG1+LixHvvbaKu1TLYbjJWPcdz3ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEGOpsfKvbw5sLtaCtOnmI9is2w0kQKxt8ZrRY4ksJIcNnLN++yGfqD98WnsGdmpyifRqbfKY4G/Gj2+XJKSMjfKa+0wsnTxRKvJ5Zq8WTTGLLFk1P83O2shJe0uitty7QPseP8xnrkbExaltcoMWN0e+T663Ck25i187Lr3FVoPAWr6N46hRPoJk+FL6uLl7g2yvkwkuAmWbjhRAKdiESQcEuRCIo2IVIBAW7EImgYBciEXay/NMjAH4XwKK73z1o+waAPwDwTrbD19z9l9ttq9Hs4NlXw3LCWJnXcavXwvJJ5/Iq3xepxQYAtXWeSFIu8CG5djksJ8EmaZ+xiVFqK0TqzHXbvK5ahndDzsL+xySZWH26TI4n8sQkKvdwwlOnw2Wy8+fPU9vx43zZpUOHI3XtFsIJOW9dDLcDwNQUl1IzOX5dta/z5avYak0AcPFSeEwWF/l1Wq2EJdZul8fRTp7sfwrggUD7n7j7vYN/2wa6EOJg2TbY3f0JAOSRJoT4h8JuvrN/xcyeN7NHzCKfY4UQtwQ3G+zfBXAHgHsBXAHwLfZGMztrZk+Z2VOtNq+DLYTYX24q2N19wd177t4H8D0A90fe+7C7n3H3M8XI5JcQYn+5qWA3sxuX0/g8gBf3xh0hxH6xE+nthwA+BeCQmV0C8HUAnzKze7G11sx5AH+4o72ZAflwtk6rG5bXAODqQljSWFrepH1O3sFrnX3gOM/WyrSoCS+cC2fE9UimGQCUy7z2W7HAZa3lenjJq61+vGacW1jyWl9fp33GxieorRdZGqrZ5PLgGMlSi23vyhW+nFQss23+GM+W21gPX1dXr/Hx+NsnX6C28ih/PlYjEuaFC1zqq62FszeLZX6e7/zw6WD7uWv8ubttsLv7lwLN39+unxDi1kK/oBMiERTsQiSCgl2IRFCwC5EICnYhEmHIv3JxmIelF4vcdkr5sHxVyXHJ60PH+VI85VykCGR7gtpW1sJZSNkil9AiyWYoFLksl83zU9Pr8uPOZMO+tNv8mBeuLlCbI1LAMJIRNzkZ/gV1JSJPMbkOANbWuFS2cI3LcmOT4W0uN/h4NCM/9Mx2+XlZv7pKbR7ZpvfDmWpzsxO0T9/CccSkV0BPdiGSQcEuRCIo2IVIBAW7EImgYBciERTsQiTCUKW3rBnG8uH7y8YmlwxmjhwJtnuHr4XlLZ5Fl8twyWhqjA/JPztzNNj+ysVV2qfb4RJP28MZgACQyXMf2zW+zVa3EWzP5/hx9bt8rbdOpOBIIfKsqG+Es/Y2N/l5yWb59ipVngG2tsYzBKcPTQfbx6Z4IdCN1VVqy7e5XNrp8qqSmSy/vicPhX0pVvg5e/vSxbAPEYlVT3YhEkHBLkQiKNiFSAQFuxCJoGAXIhGGOhvf7XSwshCuM9aOzJA3s2E3u5Ekk80Wr49WyPI6aN7nRegmR8Oz55NVPoxXNnmdvFqNH0CWJP8AwGY3XLMMALokScYjGTnNJj9md96PJXAAAMvHaEfq1vUjzx6PZEoVcnysaiSBplrhS1eVyjxZp9niY2Vk6S0A2IxcB7lsWKE4OnmY9ul3wtdABkqEESJ5FOxCJIKCXYhEULALkQgKdiESQcEuRCLsZPmnYwD+DMAsgD6Ah939O2Y2BeBHAE5iawmoL7p7eJ2mAb1+F7Va+C39/AjtVxkJJwpUxngyw+h0OHkGAKZHuMxXv87rsZXJck2zkaSKtQ5P/LBiidr6ERknX+EyTn8zLIe1WpG6dRmewOHOpZxOJ7bNsGTX7vCkm2ykpl3fuMxXjCT5NJvhxKBGRAqbnJyitqWlJWrrRpKGxklNPgAo5sPHluFDjw+eCC959bdv8OPayZO9C+CP3f1OAB8H8EdmdheAhwA87u6nATw++L8Q4hZl22B39yvu/szg9QaAlwHMA/gsgEcHb3sUwOf2yUchxB7wvr6zm9lJAB8D8CSAI+5+Bdi6IQCY2XPvhBB7xo5/LmtmIwB+AuCr7r5usYLo7+53FsBZACjld9ZHCLH37OjJbmZ5bAX6D9z9p4PmBTObG9jnAAQr9bv7w+5+xt3P5HMKdiEOim2D3bYe4d8H8LK7f/sG0y8APDh4/SCAn++9e0KIvWInH+M/AeD3AbxgZs8O2r4G4JsAfmxmXwZwAcAXtttQJpNFidQSW1wJSyQAYAhLExMTvC7ZtWUuQRw/fIraRiPLLk2NhKUyy63QPhev8+NqRpZW6sYyyorcx0omnM1liGQBRr5exTPiqAkdkh2Wi8hr0X3FvjbmImPVDzvZjuyrFqmTVx7h19zG8jK1ZQrcfyuFr6tWJOOwTOToTJbLqNsGu7v/NUCvyk9v118IcWugX9AJkQgKdiESQcEuRCIo2IVIBAW7EIkw1IKTZhlk82HJ4MjsOO3XamwE2wsFnjV2PbIk0IUrV6ntrtvCywUBwHg17GOpxAtA9vs8y6sfyRorlHgWYCtSnLNPCg4WYkUUN7k8WC7xS6RajmTtEVmuRwpiAkApIil2I5dqK5JtViRSVCNSOLJR4+MxM8uzKUtkaTMgni03lQ8Xlmy0I4VRu+FlnmJZinqyC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhGGKr0B/O4yPz9H+xRKJ4Lta6tcXusjLNcBwEqNZ6khw9fXYolXV1f49ppdnpGVLfDhr9d41l6vyyWZTi8svfQjffIFnik1UgqvbwcAjU0uOaIQzr4bGx2jXWob/Jx1mnwc6YkBAFL4MlZZoReR8jbXeEbc6CSXS48eCxeIBIDb5sO29vLbtE++H5bezPk46ckuRCIo2IVIBAW7EImgYBciERTsQiTCUGfjC/kcjpJEk2ykjtjkWLjuV4HMtAJAs8VnkdfrfBZ/KTIjfPzooWD7Wp3Xd+v1uB+FLB/+8XGe7NLu8Hu098O2+jo/rrFqxMccn6nfjCRqTMwcDW8vUiNtrR6eYQaAbJbbSsaTP6qV8LWTy/IxvH59ldrYclIAYJHFz4pVfq6vXLtEHIksNTU5GzZERAs92YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EI20pvZnYMwJ8BmMXWxP7D7v4dM/sGgD8AcG3w1q+5+y+jO8tlcXhqImhz45KMEYWnGOmTj9RHW29w+eSZl97k2yRS2fX1iCxUCdfc27KFk0UAoBZJMslFjtuJtFUtF2ifTJ8nfsC4BDgzN09tzU54TK5v8NpvqxuRxBqyPQDI5yK163ph/+uR8XVEEo1I7TcAKGV4nT+QOooA4K3VYPvMCL8+xifCCUXZHH9+70Rn7wL4Y3d/xsxGATxtZo8NbH/i7v95B9sQQhwwO1nr7QqAK4PXG2b2MgB+SxdC3JK8r+/sZnYSwMcAPDlo+oqZPW9mj5jZ5F47J4TYO3Yc7GY2AuAnAL7q7usAvgvgDgD3YuvJ/y3S76yZPWVmT9Ub/PuOEGJ/2VGwm1keW4H+A3f/KQC4+4K799y9D+B7AO4P9XX3h939jLufiU0SCSH2l22D3cwMwPcBvOzu376h/cY6Up8H8OLeuyeE2Ct2Mhv/CQC/D+AFM3t20PY1AF8ys3sBOIDzAP5wuw0ZDDkL31/KFV6brFQO2+ob67TPxuYyteUK4UwoALi6fIXazr0ZrjW32eL3zOp4RHqrcnlwaYn7v7HKZaNRIsmMV/mnqs4mH8elFV4LrwMuy7EaabkiH/t8JCOuWOT13RCpu1arhSWvdptnKhYjtQEzkWy5Zo9v8/YpLst9bD68pNTYOB+r8lj4fFrEv53Mxv81wvX5opq6EOLWQr+gEyIRFOxCJIKCXYhEULALkQgKdiESYagFJ7vdLq4theWrqSnuSi4blqgabS5BrUQy25YX+S/5Zmb5r35njk8F2xfqXLoaGeHyWmzZol6HZ6ItXuOFCBfJ+B6a4tLmzGFuyxd4Mcfa2iq19dkCS2R5KgAoZ7itWOFFMfMFLgEWG2FbO5K9NjbCZT7vch+bketxvMqvqw8cCxePbLe47Mm8iC1rpSe7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEmGo0luv76g3w5JSOVJQsLkUzkRb2+ASlOW4HNOKrOV14s7D1HaESFSvvR4pfBmRk66v88XBOn1emHH22Ay1mYezoeprvODhhbeuUtvkGJcOqxYp9OhhEagVKWDSbnJbpCQmShWeUdbpdoLtI+O8mGM1Uqy0scLXCZzs8+y7apFnHb50ObzWWyVSSPN4OVwZziLPbz3ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQhDld7y+TzmZsMZPrFCeRskq2xxZZX26fW51JEt8gyqtRqXyp55/nywfWWdy2QN45lQ65s8q2niMJfXRiYmqK3dCktNy1f5+HZqPFeqEpGM2pHMQlY8shnJNusSmQwAiu2IlIpIdlg2fGwjFV7MMdPh5/PUHM9e+0eHw1mRANB0vs1fXwlLy+UslxQLxbAfnS6X//RkFyIRFOxCJIKCXYhEULALkQgKdiESYdvZeDMrAXgCQHHw/v/u7l83sykAPwJwElvLP33R3XlmB4Bep42VhQtB21qdz+x2PDxD3nc+Q7u8wVMnzPmsr1+L2MjyPsUcT4RprPJlnIoRBWIsMhNbjiwzlK+GT+nhY3wWuRY5a7nI0krtYqQeGxnGcoXP7vecn7NCZIyLFZ7U0uj2wvva5KpA0bntzg8dpbbxiHLxm8UateWL4QSrLvgxX1wLqzzt3u5m41sA/oW734Ot5ZkfMLOPA3gIwOPufhrA44P/CyFuUbYNdt/indtSfvDPAXwWwKOD9kcBfG4/HBRC7A07XZ89O1jBdRHAY+7+JIAj7n4FAAZ/+a9AhBAHzo6C3d177n4vgKMA7jezu3e6AzM7a2ZPmdlTjXasBIEQYj95X7Px7r4K4C8BPABgwczmAGDwd5H0edjdz7j7mXJk3WshxP6ybbCb2WEzmxi8LgP4lwBeAfALAA8O3vYggJ/vk49CiD1gJ4/aOQCPmlkWWzeHH7v7/zCz/wvgx2b2ZQAXAHxhuw1lMj1U8uFaaP0SlwwanfA9aWJkgvZx8ASUE/Nchpos8SSZXn2VGLhsmMvzhItchkuHlTz3A/2wnAQAPbIAUH6UL2nUHeWSESLSWzOyRNWF6+HzvFTn58U7XGpyIqEBQKcR2WYz7H8pw/f14duPUduJQ/zauV7ndf4mp3ltw+ly+BpZjRxXsRquk5fJ8+f3tsHu7s8D+FigfRnAp7frL4S4NdAv6IRIBAW7EImgYBciERTsQiSCgl2IRDAnGWX7sjOzawDeGvz3EAC+ftPwkB/vRn68m39ofpxw96DON9Rgf9eOzZ5y9zMHsnP5IT8S9EMf44VIBAW7EIlwkMH+8AHu+0bkx7uRH+/mt8aPA/vOLoQYLvoYL0QiHEiwm9kDZvaqmb1uZgdWu87MzpvZC2b2rJk9NcT9PmJmi2b24g1tU2b2mJm9NvjL06v2149vmNnbgzF51sw+MwQ/jpnZ/zazl83sJTP7N4P2oY5JxI+hjomZlczs78zsuYEf/2HQvrvxcPeh/gOQBfAGgNsBFAA8B+CuYfsx8OU8gEMHsN9PArgPwIs3tP0nAA8NXj8E4D8ekB/fAPBvhzwecwDuG7weBXAOwF3DHpOIH0MdEwAGYGTwOg/gSQAf3+14HMST/X4Ar7v7m+7eBvDn2CpemQzu/gSAlfc0D72AJ/Fj6Lj7FXd/ZvB6A8DLAOYx5DGJ+DFUfIs9L/J6EME+D+DiDf+/hAMY0AEO4C/M7GkzO3tAPrzDrVTA8ytm9vzgY/6+f524ETM7ia36CQda1PQ9fgBDHpP9KPJ6EMEeKqVyUJLAJ9z9PgD/GsAfmdknD8iPW4nvArgDW2sEXAHwrWHt2MxGAPwEwFfdPbxO98H4MfQx8V0UeWUcRLBfAnBj3Z+jAC4fgB9w98uDv4sAfoatrxgHxY4KeO437r4wuND6AL6HIY2JmeWxFWA/cPefDpqHPiYhPw5qTAb7XsX7LPLKOIhg/xWA02Z2yswKAH4PW8Urh4qZVc1s9J3XAH4HwIvxXvvKLVHA852LacDnMYQxMTMD8H0AL7v7t28wDXVMmB/DHpN9K/I6rBnG98w2fgZbM51vAPh3B+TD7dhSAp4D8NIw/QDwQ2x9HOxg65POlwFMY2sZrdcGf6cOyI//CuAFAM8PLq65IfjxT7H1Ve55AM8O/n1m2GMS8WOoYwLgowD+frC/FwH8+0H7rsZDv6ATIhH0CzohEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCP8PkjN60H1h1XAAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(np.transpose(test_images[30], [1, 2, 0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "test_labels[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[6]]"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "test_predict_result[30]"
   ]
  }
 ]
}